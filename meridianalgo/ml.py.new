"""
Machine learning module for financial time series prediction.
Includes feature engineering, model training, and prediction utilities.
"""

import numpy as np
import pandas as pd
from typing import Tuple, Dict, List, Union, Optional
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings

class FeatureEngineer:
    """Feature engineering for financial time series data."""
    
    def __init__(self, lookback: int = 10):
        """
        Initialize feature engineer.
        
        Args:
            lookback: Number of periods to look back for feature creation
        """
        self.lookback = lookback
    
    def create_features(self, data: pd.Series) -> pd.DataFrame:
        """
        Create technical features from price/return data.
        
        Args:
            data: Time series data (prices or returns)
            
        Returns:
            DataFrame with engineered features
        """
        df = pd.DataFrame(index=data.index)
        
        # Basic features
        df['returns'] = data.pct_change()
        df['log_returns'] = np.log1p(df['returns'])
        
        # Momentum features
        for period in [5, 10, 20]:
            df[f'momentum_{period}'] = data.pct_change(periods=period)
        
        # Volatility features
        for period in [5, 10, 20]:
            df[f'volatility_{period}'] = df['returns'].rolling(period).std()
        
        # Moving averages
        for period in [10, 20, 50]:
            df[f'sma_{period}'] = data.rolling(period).mean()
            df[f'ema_{period}'] = data.ewm(span=period, adjust=False).mean()
        
        # Drop NaN values
        df = df.dropna()
        
        return df

class LSTMPredictor:
    """LSTM-based time series predictor."""
    
    def __init__(self, sequence_length: int = 10, units: int = 50, epochs: int = 50, 
                 batch_size: int = 32, validation_split: float = 0.2):
        """
        Initialize LSTM predictor.
        
        Args:
            sequence_length: Number of time steps to look back
            units: Number of LSTM units
            epochs: Number of training epochs
            batch_size: Batch size for training
            validation_split: Fraction of data to use for validation
        """
        self.sequence_length = sequence_length
        self.units = units
        self.epochs = epochs
        self.batch_size = batch_size
        self.validation_split = validation_split
        self.scaler = StandardScaler()
        self.model = None
    
    def fit(self, X: np.ndarray, y: np.ndarray) -> None:
        """
        Train the LSTM model.
        
        Args:
            X: Input features (n_samples, n_features)
            y: Target values (n_samples,)
        """
        # Scale features
        X_scaled = self.scaler.fit_transform(X)
        
        # Prepare sequences
        X_seq, y_seq = self._create_sequences(X_scaled, y)
        
        # Build and train LSTM model
        self.model = self._build_model(X_seq.shape[1], X_seq.shape[2])
        
        self.model.fit(
            X_seq, y_seq,
            epochs=self.epochs,
            batch_size=self.batch_size,
            validation_split=self.validation_split,
            verbose=1
        )
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Make predictions.
        
        Args:
            X: Input features (n_samples, n_features)
            
        Returns:
            Predicted values (n_samples,)
        """
        if self.model is None:
            raise ValueError("Model not trained. Call fit() first.")
            
        X_scaled = self.scaler.transform(X)
        X_seq = self._create_sequences(X_scaled, np.zeros(len(X)))[0]  # Dummy y
        
        # Predict and inverse transform
        y_pred = self.model.predict(X_seq, verbose=0).flatten()
        return y_pred
    
    def _create_sequences(self, X: np.ndarray, y: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Create sequences for LSTM input."""
        Xs, ys = [], []
        for i in range(len(X) - self.sequence_length):
            Xs.append(X[i:(i + self.sequence_length)])
            ys.append(y[i + self.sequence_length])
        return np.array(Xs), np.array(ys)
    
    def _build_model(self, n_timesteps: int, n_features: int) -> 'tf.keras.Model':
        """Build and compile LSTM model."""
        import tensorflow as tf
        
        model = tf.keras.Sequential([
            tf.keras.layers.LSTM(self.units, return_sequences=True, 
                               input_shape=(n_timesteps, n_features)),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.LSTM(self.units, return_sequences=False),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(1)
        ])
        
        model.compile(optimizer='adam', loss='mse')
        return model

def prepare_data_for_lstm(features: pd.DataFrame, target: pd.Series, 
                         sequence_length: int = 10, 
                         test_size: float = 0.2) -> Tuple[np.ndarray, np.ndarray, 
                                                         np.ndarray, np.ndarray]:
    """
    Prepare data for LSTM model.
    
    Args:
        features: DataFrame of features
        target: Target values
        sequence_length: Length of sequences
        test_size: Fraction of data to use for testing
        
    Returns:
        X_train, X_test, y_train, y_test
    """
    from sklearn.model_selection import train_test_split
    
    # Align features and target
    common_idx = features.index.intersection(target.index)
    features = features.loc[common_idx]
    target = target.loc[common_idx]
    
    # Split into train/test
    X_train, X_test, y_train, y_test = train_test_split(
        features.values, target.values, 
        test_size=test_size, 
        shuffle=False
    )
    
    # Scale features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Create sequences
    def create_sequences(X, y):
        Xs, ys = [], []
        for i in range(len(X) - sequence_length):
            Xs.append(X[i:(i + sequence_length)])
            ys.append(y[i + sequence_length])
        return np.array(Xs), np.array(ys)
    
    X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train)
    X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test)
    
    return X_train_seq, X_test_seq, y_train_seq, y_test_seq
